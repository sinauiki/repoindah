# -*- coding: utf-8 -*-
"""ML-M6-DT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l0B-MOJSfbiuzQOLIJ4VyaSMYvs61kxS

# **Praktikum Decission Tree**
"""

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import LeaveOneOut
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
import pandas as pd
import numpy as np

# 1. train_dataset ðŸ¡¨ milk_training.csv
train_dataset = pd.read_csv('milk_training.csv')
train_dataset

# 2. train_data ðŸ¡¨ ambil train_dataset kolom fitur (pH, Temprature, Taste, Odor, Fat, Turbidity, Colour).
train_data = train_dataset[['pH', 'Temprature', 'Taste', 'Odor', 'Fat', 'Turbidity', 'Colour']]
train_data

# 3. test_datasetðŸ¡¨ milk_testing.csv
test_dataset =  pd.read_csv('milk_testing.csv')
test_dataset

# 4. test_data ðŸ¡¨ ambil test_dataset kolom fitur (pH, Temprature, Taste, Odor, Fat, Turbidity, Colour).
test_data = test_dataset[['pH', 'Temprature', 'Taste', 'Odor', 'Fat', 'Turbidity', 'Colour']]
test_data

# 5rain_label -> ambil train_data kolom kelas (Grade)
train_label = train_dataset.loc[:,['Grade']]
train_label

# 6. test_label -> ambil test_data kolom kelas (Grade)
test_label = test_dataset.loc[:,['Grade']]
test_label

# 7. Lakukan klasifikasi test_data terhadap train_data dengan Decision Tree, dan berapakah error rationya?
import pandas as pd
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
import graphviz

dtc = DecisionTreeClassifier()
dtc.fit(train_data, train_label)
grade_result = dtc.predict(test_data)
print('Grade = ', grade_result)

acc = dtc.score(train_data, train_label)
print()
print('Akurasi Decission Tree :', acc)
err=round((1-acc)*100, 2)
print('\n\nError ratio = ', err, '%')

# 8. Menampilkan Grafik Decission Tree
dot_data = tree.export_graphviz(dtc, out_file=None, feature_names=train_data.columns.values)

graph = graphviz.Source(dot_data, format="png")
graph.render( view=True)

# Bandingkan dengan hasil dari k-NN dan Bayesian
kNN = KNeighborsClassifier(n_neighbors=3, weights='distance')
kNN.fit(train_data,train_label)

# 9) k-NN
import pandas as pd

train_data = train_dataset[['pH', 'Temprature', 'Taste', 'Odor', 'Fat', 'Turbidity', 'Colour']]
train_label = train_dataset[['Grade']]

kNN = KNeighborsClassifier(n_neighbors=3, weights='distance')
kNN.fit(train_data,train_label)
hasil = kNN.predict(test_data)

accuracy = accuracy_score(test_label, hasil)
print("Akuarsi k-NN :", accuracy)
err=round((1-accuracy)*100, 2)
print('\n\nError ratio = ', err, '%')

# 9) Naive Bayesian
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

classifier = GaussianNB()
classifier.fit(train_data, train_label)
ypred = classifier.predict(test_data)


akurasi = accuracy_score(test_label, ypred)
print('Akurasi Naive Bayesian:', akurasi)
err=round((1-akurasi)*100, 2)
print('\n\nError ratio = ', err, '%')